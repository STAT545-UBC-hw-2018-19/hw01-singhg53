---
title: "hw01_gapminder.Rmd"
author: "Gurjot Singh"
date: "16/09/2018"
output: github_document
---

# R Markdown for gapminder Exploration

## Introduction

Hello everyone today we will be exploring a dataset known as gapminder.

## Installing gapminder Dataset

First we have to install the dataset package. So we type :

`install.packages("gapminder")`

If you do not have tidyverse go ahead and it install it by applying this into your code chunk:

`install.packages("tidyverse")`

## Loading of gapminder Dataset

Now since we have installed the gapminder dataset, we can load it using the `library` function. We apply this also to tidyverse.

```{r}
library(gapminder)
library(tidyverse)
```

## Playing Around With the Dataset

We can start off by obtaining a summary of the dataset.

```{r}
summary(gapminder)
```

If we want to look at the first six rows of the data (by default) we can use the `head` function.

```{r}
head(gapminder)
```

However we can modify this function to express only two rows of data by, changing **n**

```{r}
head(gapminder, n=2)
```

If we want to look at the last or bottom rows of data we use the `tail` function:

```{r}
tail(gapminder)
```

We can again  specify the number of rows as we did before with the `head` function.

We can look at the different variables in the dataset using the `names` function.

```{r}
names(gapminder)
```

Now let's try to pick it up a notch. We can also sort for variables, lets say Canada, and observe the data when the life expectancy is greater than or equal to 60.

```{r}
gapminder %>% 
  filter(lifeExp >= 60 & country == "Canada")
```

Maybe we are curcious and want to know which country has the highest life expectancy. We could do this using the following:

```{r}
arrange(gapminder, desc(lifeExp))
```

We could do the converse and find the shortest life expectancy.

```{r}
arrange(gapminder, lifeExp)
```

We can use a plot function and plot the continents on the x axis versus the life expectancy.

```{r}
plot(gapminder$continent, gapminder$lifeExp)
```

Thank-you for exploring this dataset with me!